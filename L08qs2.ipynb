{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GhyeIVDosAzy"
   },
   "source": [
    "We repeat the greenscreen replacement from lesson 1 and lesson 5,\n",
    "but this time with nearest neighbors algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OmxJz39WsEDO"
   },
   "source": [
    "Here we display the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mLDbTVcmDZFl",
    "outputId": "bff450de-2e11-431c-bc90-5b5a189180a4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "img = image.load_img(\"imgs/greenML.png\")\n",
    "\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jx5w3UgAE2cS"
   },
   "source": [
    "Below we trim the edges of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O5ny7M6UflUb",
    "outputId": "76d611c5-2870-4c57-ee6c-4db677c38c63"
   },
   "outputs": [],
   "source": [
    "arr = image.img_to_array(img)\n",
    "# Trim off edges\n",
    "arr = arr[:696,:]\n",
    "display(image.array_to_img(arr,scale=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a rectangle of pixels, return an ndarray of all unique pixel values.\n",
    "# Selecting unique pixels now noticeably reduce classification time later,\n",
    "# e.g., from 68 seconds to 30 seconds.\n",
    "def pixel_list(pixels, name):\n",
    "    display(image.array_to_img(pixels, scale=False))\n",
    "    pixels = np.reshape(pixels, (-1, 3))\n",
    "    unique_pixels = set()\n",
    "    for p in pixels:\n",
    "        unique_pixels.add(tuple(p.tolist()))\n",
    "    unique_pixels = np.array([list(p) for p in unique_pixels])\n",
    "    print(name, len(pixels), '->', len(unique_pixels))\n",
    "    return unique_pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3ShPb7xE7Rj"
   },
   "source": [
    "In this example, we isolate out the bacground and convert it to a dataset of positive examples, `yesList`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yrdg39l6GMtH",
    "outputId": "2f6672f4-8f45-4db2-e513-4ca50ee63702"
   },
   "outputs": [],
   "source": [
    "# background\n",
    "yesList = pixel_list(arr[:,:360], 'yesList')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbLvsTBgKnC9"
   },
   "source": [
    "Now we'll isolate out the foreground and make a dataset of foreground pixels called `noList`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qcSqKYtDwqsq",
    "outputId": "07ba1240-1ea9-4f26-c504-37e467abce3d"
   },
   "outputs": [],
   "source": [
    "# foreground\n",
    "noList = pixel_list(arr[30:,547:620], 'noList')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mluPsOFNL_i8"
   },
   "source": [
    "We finalize our dataset here, with a variable `alldat` which cointains our list of pixels, and `labs` which is our list of labels for each pixel, `1` for green background pixels and `0` for foreground pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mfPVKGHoenU2"
   },
   "outputs": [],
   "source": [
    "# Build a list of pixels for both positive and negative examples.\n",
    "alldat = np.concatenate((yesList,noList))\n",
    "\n",
    "# labels\n",
    "labs = np.concatenate((np.ones(len(yesList)), np.zeros(len(noList))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlYPmhdkMDIQ"
   },
   "source": [
    "Build and train a nearest neighbors classifier to separate the background from the foreground.\n",
    "We will use k=1. Experiments showed that larger k values such as 3, 5, or 9 made little difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z03-JVB_eqHJ"
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "clf = clf.fit(alldat, labs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6KsBqtiMgiw"
   },
   "source": [
    "Now we'll display the predictions of the classifier for each pixel in our image.\n",
    "The resulting mask looks good overall, except for some glitches around the green card held by the person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P6kFOVHAeqV8",
    "outputId": "25942cf6-e742-45d5-ba9a-89f406c090d9"
   },
   "outputs": [],
   "source": [
    "# Turn the pixels in the image into a list\n",
    "flat = np.reshape(arr,(-1,3))\n",
    "out = clf.predict(flat)\n",
    "# Reshape the output as a 2 dimensional list instead of 1 dimensional\n",
    "out = np.reshape(out,(-1,1))\n",
    "# Now, concatenate this list it itself three times to make something\n",
    "#  like a color. Reshape the resulting list into the shape of the original\n",
    "#  image.\n",
    "newarr = np.reshape(np.concatenate((out, out, out),1),arr.shape)\n",
    "# Display the image\n",
    "display(image.array_to_img(newarr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EV9RKiRjMkah"
   },
   "source": [
    "With this classifier, we can replace the background with a new image of a forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UvtT5atwMnnw"
   },
   "source": [
    "We display the image of the forest, `img` below and covert the image into an array, `bkg`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXSVGHANP86Z"
   },
   "source": [
    "`composite` creates a new image based on a mask.  For each pixel in the new image:\n",
    "\n",
    "- If the `mask` predicts the pixel to be in the background, we include the corresponding pixel from `background`.  \n",
    "- If the `mask` predicts predicts the pixel to be in the foreground, we include the corresponding pixel from the `foreground`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-iPFNhhF1vaP",
    "outputId": "8ab0dcb7-a7d5-4698-ca63-7f20a2decaac"
   },
   "outputs": [],
   "source": [
    "def composite(mask, foreground, background):\n",
    "  ishift = 157\n",
    "  for i in range(min(background.shape[0],foreground.shape[0]+ishift)):\n",
    "    for j in range(min(background.shape[1], foreground.shape[1])):\n",
    "      fgi = i - ishift\n",
    "      if fgi >= 0 and not mask[fgi][j][0]: background[i][j] = foreground[fgi][j]\n",
    "  display(image.array_to_img(background,scale=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the composite image. A green outline can be seen around the person,\n",
    "similar to the results from lesson 1 and lesson 5.\n",
    "The glitches around the green card is visible, though less obvious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(\"imgs/forest.jpg\")\n",
    "bkg = image.img_to_array(img)\n",
    "composite(newarr,arr,bkg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an attempt to remove the glitches around the green card, but it didn't turn out well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative foreground that includes the green card\n",
    "noList2 = pixel_list(arr[250:,620:740], 'noList2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldat2 = np.concatenate((yesList, noList2))\n",
    "labs2 = np.concatenate((np.ones(len(yesList)), np.zeros(len(noList2))))\n",
    "\n",
    "clf2 = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "clf2 = clf2.fit(alldat2, labs2)\n",
    "\n",
    "flat = np.reshape(arr,(-1,3))\n",
    "out = clf2.predict(flat)\n",
    "out = np.reshape(out,(-1,1))\n",
    "newarr2 = np.reshape(np.concatenate((out, out, out),1),arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the new mask. The glitches around the green card is now much less obvious, though still present.\n",
    "However, we now see lots of glitches around the person, and at the upper-right corner of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(image.array_to_img(newarr2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(\"imgs/forest.jpg\")\n",
    "bkg = image.img_to_array(img)\n",
    "composite(newarr2,arr,bkg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
