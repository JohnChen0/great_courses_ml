{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFrzPlyoikd9"
   },
   "source": [
    "We will now train a decision tree and a simple neural network, a multi-layer perceptron, to classify handwritten digits in the MNIST dataset\n",
    "\n",
    "Below we load our libraries we'll be using and download the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UZ27Nqb8TBKx"
   },
   "outputs": [],
   "source": [
    "# Read in the mnist digit dataset\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import check_random_state\n",
    "import random\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# X is a pandas Dataframe with 70,000 rows and 784 columns. Each row represents\n",
    "# one 28x28 image of a digit, with each column containing one pixel of the image.\n",
    "# Pixel value ranges from 0.0 (background) to 255.0. y is a pandas Series with\n",
    "# 70,000 categorical values ranging from 0 to 9, representing digit '0' to '9'.\n",
    "# By removing return_X_y=True, fetch_openml would return an object of type\n",
    "# sklearn.utils.Bunch instead. The object has data and target attributes,\n",
    "# containing X and y values, respectively. It also has a DESCR attribute,\n",
    "# with description of the dataset. Two additional attributes, feature_names and\n",
    "# target_names, are not very useful for this dataset.\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KB0MV4C1jCAC"
   },
   "source": [
    "Next, we will divide the data into a training set and test set, randomly selecting 5000 examples for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IJ2-XGCVTBK3"
   },
   "outputs": [],
   "source": [
    "train_samples = 5000\n",
    "\n",
    "# X is in pandas format for some reason. Convert to numpy.\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# The original code randomly shuffles the data before calling train_test_split.\n",
    "# This is unnecessary as train_test_split does random selection of the data,\n",
    "# so I remove the shuffle. The original code doesn't pass a random state to\n",
    "# train_test_split, so different train/test sets are returned each time. I added\n",
    "# a random state with fixed seed, to make the selection repeatable.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=train_samples, test_size=1000,\n",
    "    random_state=check_random_state(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_IzNFu0jlH-"
   },
   "source": [
    "Let's print out the 417$^{\\text{th}}$ item in the dataset and its label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "CnYWxjv0fjPN",
    "outputId": "b59203a3-6c5e-4062-e0eb-bf0d4238fd79"
   },
   "outputs": [],
   "source": [
    "i = 417\n",
    "img = np.array(X_train[i]).reshape(28,28)\n",
    "plt.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "plt.show()\n",
    "y_train[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97zMhsOVj6aH"
   },
   "source": [
    "Let's see how a decision tree with 170 decision rules performs by training it and printing its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TO8UQY0viwRV",
    "outputId": "4ba4676c-16fd-48fa-a193-6fcbbc1a57ee"
   },
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_leaf_nodes = 170)\t\n",
    "clf = clf.fit(X_train, y_train)\t\t\t\n",
    "correct = 0\t\t\t\t\t\t\n",
    "for i in range(len(X_test)):\t\n",
    "  if clf.predict([X_test[i]]) == y_test[i]: correct = correct + 1\n",
    "  acc = [100.0* correct / len(X_test)]\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "icfBxFlPkLoE"
   },
   "source": [
    "Now let's try a simple neural network, a multi-layer perceptron with no hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AFaBc0-xpPnq",
    "outputId": "b8466520-89d6-4eae-aa8b-a03ddb513c36"
   },
   "outputs": [],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=[], max_iter = 10000, activation = 'identity', random_state=check_random_state(0))\n",
    "clf.fit(X_train, y_train)\n",
    "score = clf.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CTpGs2l-kdOs"
   },
   "source": [
    "Now, we will add one hidden layer and expand the number of hidden units from 10 to 200 in intervals of 10. We'll print the accuracy of each model given the number of hidden units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FFoZESbCupY3",
    "outputId": "97fccfaf-11f6-4d6f-e386-1f9d93f579ab"
   },
   "outputs": [],
   "source": [
    "for i in range(1,21):\n",
    "  nhidden = i*10\n",
    "  clf = MLPClassifier(hidden_layer_sizes=[nhidden], max_iter = 10000, random_state=check_random_state(0))\n",
    "  clf.fit(X_train, y_train)\n",
    "  score = clf.score(X_test, y_test)\n",
    "  print(nhidden, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQnlAyfFk-FU"
   },
   "source": [
    "To see how a model varies across multiple runs, we check it ten times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PKTMwDxcuycF",
    "outputId": "f33e5596-47d4-480c-fc98-288681135ab5"
   },
   "outputs": [],
   "source": [
    "nhidden = 170\n",
    "random_state=check_random_state(0)\n",
    "for i in range(10):\n",
    "  clf = MLPClassifier(hidden_layer_sizes=[nhidden], max_iter = 10000, random_state=random_state)\n",
    "  clf.fit(X_train, y_train)\n",
    "  score = clf.score(X_test, y_test)\n",
    "  print(nhidden,score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the best classifier we saw above, and show its errors.\n",
    "# Some of the error cases are hard, even for human eyes, but some are easy for human.\n",
    "nhidden = 180\n",
    "clf = MLPClassifier(hidden_layer_sizes=[nhidden], max_iter = 10000, random_state=check_random_state(0))\n",
    "clf.fit(X_train, y_train)\n",
    "predicts = clf.predict(X_test)\n",
    "for X, y, predict in zip(X_test, y_test, predicts):\n",
    "  if predict != y:\n",
    "    img = np.array(X).reshape(28,28)\n",
    "    plt.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "    plt.show()\n",
    "    print('Predict:', predict, 'Actual:', y)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "L04.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
