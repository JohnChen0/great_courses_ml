{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFrzPlyoikd9"
   },
   "source": [
    "We will now train a decision tree and a simple neural network, a multi-layer perceptron, to classify handwritten digits in the MNIST dataset\n",
    "\n",
    "Below we load our libraries we'll be using and download the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UZ27Nqb8TBKx"
   },
   "outputs": [],
   "source": [
    "# Read in the mnist digit dataset\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import check_random_state\n",
    "import random\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KB0MV4C1jCAC"
   },
   "source": [
    "Next, we will divide the data into a training set and test set, randomly selecting 5000 examples for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IJ2-XGCVTBK3"
   },
   "outputs": [],
   "source": [
    "train_samples = 5000\n",
    "\n",
    "# X is in pandas format for some reason. Convert to numpy.\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "random_state = check_random_state(0)\n",
    "permutation = random_state.permutation(X.shape[0])\n",
    "X = X[permutation]\n",
    "y = y[permutation]\n",
    "X = X.reshape((X.shape[0], -1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=train_samples, test_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_IzNFu0jlH-"
   },
   "source": [
    "Let's print out the 417$^{\\text{th}}$ item in the dataset and its label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "CnYWxjv0fjPN",
    "outputId": "b59203a3-6c5e-4062-e0eb-bf0d4238fd79"
   },
   "outputs": [],
   "source": [
    "i = 417\n",
    "img = np.array(X_train[i]).reshape(28,28)\n",
    "plt.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "plt.show()\n",
    "y_train[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97zMhsOVj6aH"
   },
   "source": [
    "Let's see how a decision tree with 170 decision rules performs by training it and printing its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TO8UQY0viwRV",
    "outputId": "4ba4676c-16fd-48fa-a193-6fcbbc1a57ee"
   },
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_leaf_nodes = 170)\t\n",
    "clf = clf.fit(X_train, y_train)\t\t\t\n",
    "correct = 0\t\t\t\t\t\t\n",
    "for i in range(len(X_test)):\t\n",
    "  if clf.predict([X_test[i]]) == y_test[i]: correct = correct + 1\n",
    "  acc = [100.0* correct / len(X_test)]\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "icfBxFlPkLoE"
   },
   "source": [
    "Now let's try a simple neural network, a multi-layer perceptron with no hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AFaBc0-xpPnq",
    "outputId": "b8466520-89d6-4eae-aa8b-a03ddb513c36"
   },
   "outputs": [],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=[], max_iter = 10000, activation = 'identity')\n",
    "clf.fit(X_train, y_train)\n",
    "score = clf.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CTpGs2l-kdOs"
   },
   "source": [
    "Now, we will add one hidden layer and expand the number of hidden units from 10 to 200 in intervals of 10. We'll print the accuracy of each model given the number of hidden units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FFoZESbCupY3",
    "outputId": "97fccfaf-11f6-4d6f-e386-1f9d93f579ab"
   },
   "outputs": [],
   "source": [
    "for i in range(1,21):\n",
    "  nhidden = i*10\n",
    "  clf = MLPClassifier(hidden_layer_sizes=[nhidden], max_iter = 10000)\n",
    "  clf.fit(X_train, y_train)\n",
    "  score = clf.score(X_test, y_test)\n",
    "  print(nhidden, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQnlAyfFk-FU"
   },
   "source": [
    "To see how a model varies across multiple runs, we check it ten times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PKTMwDxcuycF",
    "outputId": "f33e5596-47d4-480c-fc98-288681135ab5"
   },
   "outputs": [],
   "source": [
    "nhidden = 170\n",
    "for i in range(10):\n",
    "  clf = MLPClassifier(hidden_layer_sizes=[nhidden], max_iter = 10000)\n",
    "  clf.fit(X_train, y_train)\n",
    "  score = clf.score(X_test, y_test)\n",
    "  print(nhidden,score)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "L04.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
