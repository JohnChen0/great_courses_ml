{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bFSFDwOuJHBW"
   },
   "source": [
    "In this notebook, we will build a recomendation system for academic papers. \n",
    "\n",
    "We will be using two data files.\n",
    "- `cb.txt` contains the titles of the papers, together with a label indicating whether a person likes it or not. The label is not used by the recommendation system, but is used by the feedback logic. The label (0 or 1) appears on column 1, and the title appears on the remainder of the line, separated from the label by a space.\n",
    "- `vocab2.txt` contains the words in the titles of the academic papers. The first four columns of each line contains the count of how many times the word appears (only approximately matches cb.txt), and the word appears on the remainder of the line, separated from the count by a space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwCUD_TANklv"
   },
   "source": [
    "Here we write a few functions that will help us in processing the data:\n",
    "\n",
    "- `readvocab` creates a `vocab_dict` associating a unique ID with each word that occurs in our paper titles\n",
    "- `tokenize` turns each set of words in a title, `string`, into a count of the number of times each word in the title occurs\n",
    "- `getdat`, which takes the titles and returns a list of titles with their word counts, `dat`, and a list of labels indicating if the user found the title interesting, `labs`\n",
    "\n",
    "We will use our function to process our data to get our vectorized titles, `dat`, and their labels `labs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V-Fu_cwlZGIU"
   },
   "outputs": [],
   "source": [
    "# read in the vocabulary file \n",
    "def readvocab():\n",
    "   # keep track of the number of words\n",
    "    lexiconsize = 0\n",
    "   # initialize an empty dictionary\n",
    "    vocab_dict = {}\n",
    "   # create a catch-all feature (vector component) for all unknown words\n",
    "    vocab_dict[\"@unk\"] = lexiconsize\n",
    "    lexiconsize += 1\n",
    "   # read in the vocabulary file\n",
    "    with open(\"data/vocab2.txt\", \"r\") as f:\n",
    "        data = f.readlines()\n",
    "   # Process the file a line at a time.\n",
    "    for line in data:\n",
    "        # The count is the first 3 characters\n",
    "        count = int(line[0:4])\n",
    "        # The word is the rest of the string\n",
    "        token = line[5:-1]\n",
    "       # Create a feature if itâ€™s appeared at least twice\n",
    "        if count > 1: \n",
    "            vocab_dict[token] = lexiconsize\n",
    "            lexiconsize += 1\n",
    "    # squirrel away the total size for later reference\n",
    "    vocab_dict[\"@size\"] = lexiconsize\n",
    "    return(vocab_dict)\n",
    "\n",
    "# vocab_dict is dict[str, int], with the following keys:\n",
    "# * vocab_dict[\"@unk\"] == 0, representing words unknown to the vocab.\n",
    "# * vocab_dict[\"@size\"] is the size of the vocab, including @unk, but not including @size itself.\n",
    "# * All other keys are words in the vocab, with values being their unique IDs. Each ID is an int between 1 and @size-1.\n",
    "vocab_dict = readvocab()\n",
    "\n",
    "# Turn string str into a vector.\n",
    "def tokenize(string, vocab_dict):\n",
    "  # initially the vector is all zeros\n",
    "  vec = [0] * vocab_dict[\"@size\"]\n",
    "  unk = vocab_dict[\"@unk\"]\n",
    "  # for each word\n",
    "  for t in string.split(\" \"):\n",
    "   # if the word has a feature, add one to the corresponding feature\n",
    "   # otherwise, count it as an unk\n",
    "    vec[vocab_dict.get(t, unk)] += 1\n",
    "  return(vec)\n",
    "\n",
    "# read in labeled examples and turn the strings into vectors\n",
    "def getdat(vocab_dict):\n",
    "    with open(\"data/cb.txt\", \"r\") as f:\n",
    "        data = f.readlines()\n",
    "    dat = []\n",
    "    labs = []\n",
    "    for line in data:\n",
    "        labs = labs + [int(line[0])]\n",
    "        dat = dat + [tokenize(line[2:], vocab_dict)]\n",
    "    return(dat, labs)\n",
    "\n",
    "(dat, labs) = getdat(vocab_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53UHLTOiSdXl"
   },
   "source": [
    "We define two additional helper functions to make our recommendations:\n",
    "\n",
    "- `playgame` makes `rounds / b` recommendations using `chooser` and is given a `score`.  For the first `alpha` rounds the selections are random. It makes one recommendation per round.\n",
    "\n",
    "- `argmax` returns the index from `indices` associated with the item in the `vals` list with the highest value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2s0aTNrZGL0"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def playgame(chooser, rounds, alpha):\n",
    "  curitem = 0\n",
    "  score = 0\n",
    "  trainset = []\n",
    "  trainlabs = []\n",
    "  b = 5\n",
    "  clf = MultinomialNB()\n",
    "\n",
    "  while curitem < rounds:\n",
    "    chosenitem = chooser(curitem, b, trainset, trainlabs, alpha, clf)\n",
    "    score = score + labs[chosenitem]\n",
    "    trainset = trainset + [dat[chosenitem]]\n",
    "    trainlabs = trainlabs + [labs[chosenitem]]\n",
    "    curitem += b\n",
    "  return(score)\n",
    "\n",
    "def argmax(indices, vals):\n",
    " best = max(vals)\n",
    " for i in range(len(indices)):\n",
    "   if vals[i] == best: \n",
    "     return(indices[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CrscWdZXWNzd"
   },
   "source": [
    "This function is our choosing function, `probachooser` and chooses between `b` options. `currentitem` is the initial item to consider.  `trainset` represents the results of previous selections. \n",
    "\n",
    "\n",
    "If we have not yet made `alpha` selections, the selection is random. \n",
    "\n",
    "If we have made `alpha` selections in the past, we fit our `clf` Naive Bayes model using the traing data of academic papers by title, `trainset`, and training labels for if the academic papers were interesting, `trainlabs`.  After we fit our `clf` model, we use it to select the item most likely to be labeled as interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dlCqy7KhZGP9"
   },
   "outputs": [],
   "source": [
    "def probachooser(curitem, b, trainset, trainlabs, alpha, clf):\n",
    "  if len(trainset) == alpha:\n",
    "    clf = clf.fit(trainset, trainlabs)\n",
    "#comment?\n",
    "  if len(trainset) < alpha:\n",
    "    chosenitem = random.randint(curitem,curitem+b-1)\n",
    "  else:\n",
    "    yhat = clf.predict_proba(dat[curitem:(curitem+b)])\n",
    "    chosenitem = argmax(range(curitem,curitem+b), [p for (c,p) in yhat])\n",
    "  return(chosenitem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dt6mp5vYdS6I"
   },
   "source": [
    "We will see how the number of rounds with random choices, `alpha` affects the final score.  We will run our `playgame` function with `alpha` values ranging from 10 to 200.  We will plot our scores below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 10934,
     "status": "ok",
     "timestamp": 1593607861232,
     "user": {
      "displayName": "Michael Littman",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64",
      "userId": "06751891446459829367"
     },
     "user_tz": 240
    },
    "id": "kjaJpElLZGSz",
    "outputId": "bc2c5ce0-d380-439c-af01-89172a35fd97"
   },
   "outputs": [],
   "source": [
    "# Exactly half of the entries in trainlabs have value of 1, so an algorithm that\n",
    "# always randomly select a title should get 50% right. The distribution of favorable\n",
    "# titles is not completely even, but close. The code below only looks at the first\n",
    "# 1000 titles, out of which 49.4% have label 1.\n",
    "\n",
    "# Test below shows that a small alpha (somewhere around 10 to 20) is good enough for\n",
    "# training the classifier. A larger alpha *might* be able to generate a better model,\n",
    "# but it also reduces the number of time the model can be used. In particular, when\n",
    "# alpha == 195, the algorithm would make 195 random recommendations, and then use\n",
    "# the classifier to make only 5 recommendations, thus the score would be around 50%\n",
    "# regardless of how good the classifier is.\n",
    "\n",
    "# An approach to get better score (though at the expense of more computation power)\n",
    "# might be start training after a few rounds, but periodically re-train the model\n",
    "# as more data are gathered. This is explored in following cells.\n",
    "\n",
    "alphas = range(10,200,5)\n",
    "ress = []\n",
    "for alpha in alphas:\n",
    "  res = playgame(probachooser, 1000, alpha)\n",
    "  print(alpha, res)\n",
    "  ress += [res]\n",
    "  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(alphas, ress)\n",
    "plt.plot(alphas, ress)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zk6cY0iQdkqS"
   },
   "source": [
    "We rewrite our `probachooser` function so that `alpha` is now used as a smoothing parameter for our Naive Bayes model, ranging between 0 and 1.  We train our Naive Bayes classifier on every data element using our smoothing parameter in our Naive Bayes model, `alpha`. The `chosenitem` returned is just the one our classifier thinks is most likely to be interesting.\n",
    "\n",
    "We also will rewrite our `playgame` function to accomodate the changes we made in `probachooser`.\n",
    "\n",
    "Given these changes, we will plot how our score changes as we vary `alpha` from 0.00005 to 1. Note: Can take 15-20 minutes to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tFWoqjQcZGV0"
   },
   "outputs": [],
   "source": [
    "def probachooser(curitem, b, trainset, trainlabs, alpha):\n",
    "  # Original code just checks for len(trainset) == 0. However, when all\n",
    "  # labels are the same, the classifier can only predict for that label.\n",
    "  # This causes clf.predict_proba to return an n*1 array instead of\n",
    "  # n*2 array, and results in an error later.\n",
    "  if len(set(trainlabs)) < 2:\n",
    "    chosenitem = random.randint(curitem,curitem+b-1)\n",
    "  else:\n",
    "    clf = MultinomialNB(alpha=alpha)\n",
    "    clf = clf.fit(trainset, trainlabs)\t\n",
    "    yhat = clf.predict_proba(dat[curitem:(curitem+b)])\n",
    "    chosenitem = argmax(range(curitem,curitem+b), [p for (c,p) in yhat])\n",
    "  return(chosenitem)\n",
    "\n",
    "def playgame(chooser, rounds, alpha):\n",
    "  curitem = 0\n",
    "  score = 0\n",
    "  trainset = []\n",
    "  trainlabs = []\n",
    "  b = 5\n",
    "\n",
    "  while curitem < rounds:\n",
    "    chosenitem = chooser(curitem, b, trainset, trainlabs, alpha)\n",
    "    score = score + labs[chosenitem]\n",
    "    trainset = trainset + [dat[chosenitem]]\n",
    "    trainlabs = trainlabs + [labs[chosenitem]]\n",
    "    curitem += b\n",
    "  return(score)\n",
    "\n",
    "rep = 10\n",
    "alphas = [0.00005, 0.0001, 0.0002, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1.0]\n",
    "ress = []\n",
    "mins = []\n",
    "maxs = []\n",
    "for alpha in alphas:\n",
    "  print(\"Processing\", alpha)\n",
    "  total = 0\n",
    "  res = []\n",
    "  for i in range(rep):\n",
    "    res += [playgame(probachooser, 1000, alpha)]\n",
    "  ress += [sum(res)/rep]\n",
    "  mins += [min(res)]\n",
    "  maxs += [max(res)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bXWNnxLbm10s"
   },
   "source": [
    "We plot the results of varying our smoothing parameter `alpha` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 1282151,
     "status": "ok",
     "timestamp": 1593609219453,
     "user": {
      "displayName": "Michael Littman",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64",
      "userId": "06751891446459829367"
     },
     "user_tz": 240
    },
    "id": "TB0MKJK6ZGZO",
    "outputId": "93b7c678-9136-4dc0-bf34-0c187c3a46b2"
   },
   "outputs": [],
   "source": [
    "# alpha is the smoothing factor. It accounts for features not present in the\n",
    "# learning samples and prevents zero probabilities. See\n",
    "# https://scikit-learn.org/0.21/modules/naive_bayes.html#multinomial-naive-bayes\n",
    "\n",
    "# Original code used linear scale on both axes. This caused small alpha values\n",
    "# to crowd into each other. I changed the x-axis to log scale. The plots shows\n",
    "# that as alpha increases, the score first starts to increase, peaking around\n",
    "# alpha of 0.01, and then starts decreasing again.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(alphas, ress)\n",
    "plt.plot(alphas, ress)\n",
    "plt.xscale('log')\n",
    "# plt.fill_between(alphas, mins, maxs, alpha=0.6)   \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "L12.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
