{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u-O-IaFDLM3u"
   },
   "source": [
    "In this notebook we will build a speech recognition model.  \n",
    "\n",
    "Below we'll import the libraries we'll be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2727,
     "status": "ok",
     "timestamp": 1596142272224,
     "user": {
      "displayName": "Michael Littman",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64",
      "userId": "06751891446459829367"
     },
     "user_tz": 240
    },
    "id": "wrWNC6CiH7Dd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa   #for audio processing\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VuKhes1QLe3b"
   },
   "source": [
    "Next, we'll download the dataset of speech commands from tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17694,
     "status": "ok",
     "timestamp": 1596142287202,
     "user": {
      "displayName": "Michael Littman",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64",
      "userId": "06751891446459829367"
     },
     "user_tz": 240
    },
    "id": "LUrISUQjkscm",
    "outputId": "46d974c1-eca8-4457-c8a5-6432e9a69a07"
   },
   "outputs": [],
   "source": [
    "!wget http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JZVW2lmaLkHz"
   },
   "source": [
    "Here, we unzip the file we downloaded from tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 58040,
     "status": "ok",
     "timestamp": 1596142331149,
     "user": {
      "displayName": "Michael Littman",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64",
      "userId": "06751891446459829367"
     },
     "user_tz": 240
    },
    "id": "52b5XAo0k1lT"
   },
   "outputs": [],
   "source": [
    "!mkdir speech_commands\n",
    "!tar -C ./speech_commands -xf speech_commands_v0.01.tar.gz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eI-bgCqOLoEA"
   },
   "source": [
    "Let's plot the waveform of an example spoken command, `samples`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 62373,
     "status": "ok",
     "timestamp": 1596142338747,
     "user": {
      "displayName": "Michael Littman",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64",
      "userId": "06751891446459829367"
     },
     "user_tz": 240
    },
    "id": "DVUj3Z5cI4Vm",
    "outputId": "b12a98d8-1a32-4101-ab29-6477a2d407c4"
   },
   "outputs": [],
   "source": [
    "train_path = 'speech_commands/'\n",
    "filename = train_path+'no/afe0b87d_nohash_0.wav'\n",
    "samples, sample_rate = librosa.load(filename, sr = 16000)\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.set_title('Raw signal of ' + filename)\n",
    "ax1.set_xlabel('time')\n",
    "ax1.set_ylabel('Amplitude')\n",
    "ax1.plot(np.linspace(0, sample_rate/len(samples), sample_rate), samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rODDxUb3Lx_O"
   },
   "source": [
    "Below we will play the the `samples` audio command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 53453,
     "status": "ok",
     "timestamp": 1596142338748,
     "user": {
      "displayName": "Michael Littman",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64",
      "userId": "06751891446459829367"
     },
     "user_tz": 240
    },
    "id": "RURz8GG2vPHr",
    "outputId": "2e66f477-4ddb-43f9-91f3-30fc3578e83f"
   },
   "outputs": [],
   "source": [
    "ipd.Audio(samples,rate=sample_rate,autoplay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Ve2s44HL6G5"
   },
   "source": [
    "Below we load the data into `all_wavs` and their respective labels into `all_labs`.  The labels are either `yes` or `no`.\n",
    "\n",
    "We'll also print the number of examples in `all_wavs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 440915,
     "status": "ok",
     "timestamp": 1593903868705,
     "user": {
      "displayName": "Michael Littman",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64",
      "userId": "06751891446459829367"
     },
     "user_tz": 240
    },
    "id": "W--i8r_iwMv-",
    "outputId": "c86b574f-84d4-431a-ddd5-2b24b46cc0ab"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory = 'speech_commands/'\n",
    "\n",
    "all_wavs = []\n",
    "all_labs = []\n",
    "for label in ['yes', 'no']:\n",
    "    print(label)\n",
    "    wavs = [f for f in os.listdir(directory + label) if f.endswith('.wav')]\n",
    "    for wav in wavs:\n",
    "        samples, sample_rate = librosa.load(directory + label + '/' + wav, sr = 16000)\n",
    "        if(len(samples)== 16000): \n",
    "            all_wavs.append(samples)\n",
    "            all_labs.append(label)\n",
    "print(len(all_wavs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5OS6-Zk1NwJd"
   },
   "source": [
    "Below we split our training and test data.  `X_train` is our processed audio files for training and `y_train` are their labels.  `X_test` and `y_test` are our test audio files and their labels, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mi2-T32hwb6T"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "all_wavs = np.array(all_wavs).reshape(-1,16000,1)\n",
    "all_labs = np.array([lab == 'yes' for lab in all_labs])\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_wavs,all_labs,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qyYmvoBbOcMv"
   },
   "source": [
    "In the following lines, we will build together the layers of our model for speech recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15330,
     "status": "ok",
     "timestamp": 1593904125706,
     "user": {
      "displayName": "Michael Littman",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64",
      "userId": "06751891446459829367"
     },
     "user_tz": 240
    },
    "id": "_gLlhz_vy3V6",
    "outputId": "71a4423e-1104-4193-b324-772dfca87cfe"
   },
   "outputs": [],
   "source": [
    "!pip install keras=='2.3.1'\n",
    "from keras.layers import Conv1D, Input, MaxPooling1D, Flatten, Dense\n",
    "from keras.models import Model\n",
    " \n",
    "inputs = Input(shape=(16000,1))\n",
    " \n",
    "#First Conv1D layer\n",
    "conv = Conv1D(8,13, padding='valid', activation='relu', strides=1)(inputs)\n",
    "conv = MaxPooling1D(3)(conv)\n",
    " \n",
    "#Second Conv1D layer\n",
    "conv = Conv1D(16, 11, padding='valid', activation='relu', strides=1)(conv)\n",
    "conv = MaxPooling1D(3)(conv)\n",
    " \n",
    "#Third Conv1D layer\n",
    "conv = Conv1D(32, 9, padding='valid', activation='relu', strides=1)(conv)\n",
    "conv = MaxPooling1D(3)(conv)\n",
    " \n",
    "#Fourth Conv1D layer\n",
    "conv = Conv1D(64, 7, padding='valid', activation='relu', strides=1)(conv)\n",
    "conv = MaxPooling1D(3)(conv)\n",
    " \n",
    "#Flatten layer\n",
    "conv = Flatten()(conv)\n",
    " \n",
    "#Dense Layer 1\n",
    "conv = Dense(256, activation='relu')(conv)\n",
    " \n",
    "#Dense Layer 2\n",
    "conv = Dense(128, activation='relu')(conv)\n",
    " \n",
    "outputs = Dense(1, activation='sigmoid')(conv)\n",
    " \n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IuVQFr34Oj2y"
   },
   "source": [
    "We then `fit` the model.  We use a `mean_squared_error` `loss` and optimize the weigths using use `adam` as our `optimizer`. We iterate of the data 15 times.  Each time, or `epoch`, we print out the `accuracy` and `loss` of our model so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 38824,
     "status": "ok",
     "timestamp": 1593904155610,
     "user": {
      "displayName": "Michael Littman",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64",
      "userId": "06751891446459829367"
     },
     "user_tz": 240
    },
    "id": "oTCjBNo9y8XT",
    "outputId": "5eea60a0-f7a4-46a0-9ebd-046f409f9e4f"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer='adam',metrics=['accuracy'])\n",
    " \n",
    "model.fit(X_train, y_train ,epochs=15, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l7IGY2JePP5B"
   },
   "source": [
    "We then report the final `accuracy` and `loss` on the `X_test` and `y_test` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2084,
     "status": "ok",
     "timestamp": 1593904700475,
     "user": {
      "displayName": "Michael Littman",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64",
      "userId": "06751891446459829367"
     },
     "user_tz": 240
    },
    "id": "zbnF7hTXy_zr",
    "outputId": "cac1f552-df93-4fcc-e1e8-2fdd98f0c6e1"
   },
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1223,
     "status": "ok",
     "timestamp": 1593904816895,
     "user": {
      "displayName": "Michael Littman",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64",
      "userId": "06751891446459829367"
     },
     "user_tz": 240
    },
    "id": "4TyyipuYIUPP",
    "outputId": "35804b5f-5fe3-4c0d-a0c2-ad73f9321655"
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1377,
     "status": "ok",
     "timestamp": 1593904949712,
     "user": {
      "displayName": "Michael Littman",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64",
      "userId": "06751891446459829367"
     },
     "user_tz": 240
    },
    "id": "5haffyVcIVly",
    "outputId": "3a80ff6f-e7a6-496b-e72e-06f2a6991663"
   },
   "outputs": [],
   "source": [
    "sum(sum(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NKERzJE8IaRq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "L20.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
