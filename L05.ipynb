{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GhyeIVDosAzy"
   },
   "source": [
    "Let's do a simple greenscreen replacement with a machine-learning model.\n",
    "\n",
    "We will:\n",
    "- download and display an image\n",
    "- pre-process the pixels, labeling background and foreground pixels\n",
    "- train a model to identify green background pixels\n",
    "- use the predictions of the model swap the green screen background for an image of a forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8PFoSOH4XZiv",
    "outputId": "412ce64f-58c5-46ef-bc9a-1842517e359c"
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/mlittmancs/great_courses_ml/raw/master/imgs/greenML.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OmxJz39WsEDO"
   },
   "source": [
    "Here we download and display the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mLDbTVcmDZFl",
    "outputId": "bff450de-2e11-431c-bc90-5b5a189180a4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "img = image.load_img(\"greenML.png\")\n",
    "\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jx5w3UgAE2cS"
   },
   "source": [
    "Below we trim the edges of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O5ny7M6UflUb",
    "outputId": "76d611c5-2870-4c57-ee6c-4db677c38c63"
   },
   "outputs": [],
   "source": [
    "arr = image.img_to_array(img)\n",
    "# Trim off edges\n",
    "arr = arr[:697,:]\n",
    "display(image.array_to_img(arr,scale=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3ShPb7xE7Rj"
   },
   "source": [
    "In this example, we isolate out the bacground and convert it to a dataset of positive examples, `yesList`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yrdg39l6GMtH",
    "outputId": "2f6672f4-8f45-4db2-e513-4ca50ee63702"
   },
   "outputs": [],
   "source": [
    "# background\n",
    "tmp = arr[:,:360]\n",
    "display(image.array_to_img(tmp,scale=False))\n",
    "\n",
    "yesList = np.reshape(tmp,(-1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_eHUJXK6HVwh"
   },
   "source": [
    "Below we print the number of values in each dimension of `tmp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GzhvRd0kAtk1",
    "outputId": "9c75ba26-e7f2-4791-c5b1-b6b07f3cb65c"
   },
   "outputs": [],
   "source": [
    "tmp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vojIrV_jKKsl"
   },
   "source": [
    "Below we print the number of values in each dimension of `yesList`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "llLbxVFBBoKQ",
    "outputId": "f5a75fca-fb12-42b2-ae0d-b94f08732e05"
   },
   "outputs": [],
   "source": [
    "yesList.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aw8Vfo6HKLug"
   },
   "source": [
    "Below we build `seen` dictionary of the unique pixel colors in `yesList`.  For all keys in the dictionary, the value is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ACqoSeLO1xFV",
    "outputId": "9c8bda39-5b61-417d-fe91-81f109cffc6f"
   },
   "outputs": [],
   "source": [
    "seen = {}\n",
    "for c in yesList:\n",
    "  col = str(c)\n",
    "  if col not in seen: seen[col] = 1\n",
    "len(seen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbLvsTBgKnC9"
   },
   "source": [
    "Now we'll isolate out the foreground and make a dataset of foreground pixels called `noList`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qcSqKYtDwqsq",
    "outputId": "07ba1240-1ea9-4f26-c504-37e467abce3d"
   },
   "outputs": [],
   "source": [
    "# foreground\n",
    "tmp = arr[30:,547:620]\n",
    "display(image.array_to_img(tmp,scale=False))\n",
    "\n",
    "noList = np.reshape(tmp,(-1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMoczmlvL86-"
   },
   "source": [
    "Below is the number of values in each dimension of the full image, corresponding to the height, width, and RGB (red, green, blue) colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uf1CSKMBAIWl",
    "outputId": "8f4e2a2e-ed51-46b8-9435-5eb918fe3da3"
   },
   "outputs": [],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mluPsOFNL_i8"
   },
   "source": [
    "We finalize our dataset here, with a variable `alldat` which cointains our list of pixels, and `labs` which is our list of labels for each pixel, `0` for green background pixels and `1` for foreground pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mfPVKGHoenU2"
   },
   "outputs": [],
   "source": [
    "# Build a list of pixels for both positive and negative examples.\n",
    "alldat = np.concatenate((yesList,noList))\n",
    " \n",
    "# labels\n",
    "labs = np.concatenate((np.ones(len(yesList)), np.zeros(len(noList))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlYPmhdkMDIQ"
   },
   "source": [
    "Here, we'll build a classifier to separate the background from the foreground\n",
    "\n",
    "We define a `loss` function.  The `loss` takes in our data, `alldat`, our labels `labs`, and our current weights, `w`.  We will make adjustments to `w` based on this loss function.  To make a prediction, we will multiply `w` by `alldat`, and pass it through a sigmoid function to get our predictions, `y`.  We will then compare our predictions `y` to their true labels `labs` using a squared loss, the sum of the squared difference between `labs`, our true labels, and `y` our predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z03-JVB_eqHJ"
   },
   "outputs": [],
   "source": [
    "# Add an additional column to the data corresponding to \n",
    "#  the offset parameter.\n",
    "alldat = np.concatenate((alldat,np.ones((len(alldat),1))),1)\n",
    "\n",
    "# Compute the loss of the rule specified by weights w with respect\n",
    "#  to the data alldat labeled with labs\n",
    "def loss(w, alldat, labs):\n",
    "  # Compute a weighted sum for each instance\n",
    "  h = np.matmul(alldat,w)\n",
    "  # transform the sum using the sigmoid function\n",
    "  y = 1/(1 + np.exp(-h))\n",
    "  # take the difference between the labels and the output of the \n",
    "  #  sigmoid, squared, then sum up over all instances to get the \n",
    "  #  total loss.\n",
    "  loss = np.sum((labs - y)**2)\n",
    "  return(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FUhyszdcMKN5"
   },
   "source": [
    "To see how our `loss` function works, we'll print ou the loss of 10 random sets of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oa7hN6xSQfiH",
    "outputId": "7daf01cc-cf33-4490-bc96-119588cc8aad"
   },
   "outputs": [],
   "source": [
    "# repeat 10 times\n",
    "for i in range(10):\n",
    "  # pick a random vector of weights, with values between -1 and 1\n",
    "  w = np.random.random(4)*2-1\n",
    "  # report the loss\n",
    "  print(w, loss(w, alldat, labs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-vkgAKUMNFC"
   },
   "source": [
    "Now we'll train the model, by creating a `fit` function to fit the model to the data.  We will update the weights through gradient descent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l44hJI6tXvox",
    "outputId": "fa7a591a-bc0c-4be8-9f22-3f5409b54193"
   },
   "outputs": [],
   "source": [
    "def fit(w,alldat,labs):\n",
    "  # alpha represents how big of a step we’ll\n",
    "  #  be taking in the direction of the derivative.\n",
    "  #  It’s called the learning rate.\n",
    "  alpha = 0.1\n",
    "\n",
    "  # We'll stop searching when we're at a (near) local min\n",
    "  done = False\n",
    "  while not done:\n",
    "    # Every 100 iterations or so, let’s\n",
    "    #  take a peek at the weights, the learning\n",
    "    #  rate, and the current loss\n",
    "    if np.random.random() < 0.01: print(w, alpha, loss(w,alldat,labs))\n",
    "    # The next few lines compute the gradient\n",
    "    #  of the loss function. The details aren’t\n",
    "    #  important right now.\n",
    "    # delta_w is the change in the weights\n",
    "    #  suggested by the gradient\n",
    "    h = np.matmul(alldat,w)\n",
    "    y = 1/(1 + np.exp(-h))\n",
    "#    delta_w = np.add.reduce(np.reshape((labs-y) * np.exp(-h)/(1 + np.exp(-h))**2,(len(y),1)) * alldat)\n",
    "    delta_w = np.add.reduce(np.reshape((labs-y) * np.exp(-h)*y**2,(len(y),1)) * alldat)\n",
    "    # if we take a step of size alpha and update\n",
    "    #  the weights, we’ll get new weights neww.\n",
    "    current_loss = loss(w,alldat,labs)\n",
    "    alpha *= 2\n",
    "    neww = w + alpha* delta_w\n",
    "    while loss(neww,alldat,labs) >= current_loss and not done:\n",
    "      alpha /= 2\n",
    "      if alpha*max(abs(delta_w)) < 0.0001: \n",
    "        done = True\n",
    "        print(alpha,delta_w)\n",
    "      else: neww = w + alpha* delta_w\n",
    "    if not done: w = neww\n",
    "  return(w)\n",
    "\n",
    "# w = fit([-2.0, 0, 0.093, -0.713],alldat,labs)\n",
    "\n",
    "w = [ 0.786,  0.175, -0.558, -0.437]\n",
    "w = fit(w,alldat,labs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B6p4xPqaMTds"
   },
   "source": [
    "We'll now print the final `loss` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KQI6jeTeeBCC",
    "outputId": "56c851c6-eb1a-4f79-b721-99fd8c264317"
   },
   "outputs": [],
   "source": [
    "print(loss([-0.138, -1.62, -1.00, -1.00], alldat, labs))\n",
    "print(loss(w, alldat, labs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-lDOwC9YMcBH"
   },
   "source": [
    "These are the weights of our learned classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LDMfFw-Nc26s",
    "outputId": "100196e3-0560-405f-c8d6-e80222e5e80a"
   },
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6KsBqtiMgiw"
   },
   "source": [
    "Now we'll display the predictions of the classifier for each pixel in our image.  We reshape our image, `arr` and multiply it by our learned weights, `w` to get our predictions for each pixel belonging to the background, `out`.  We convert `out` into a binary array and reshape to display as an image; `newarr` is our binarized prediction image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P6kFOVHAeqV8",
    "outputId": "25942cf6-e742-45d5-ba9a-89f406c090d9"
   },
   "outputs": [],
   "source": [
    "# Turn the pixels in the image into a list\n",
    "flat = np.reshape(arr,(-1,3))\n",
    "# Stick a \"1\" at the end of each color\n",
    "flat = np.concatenate((flat,np.ones((len(flat),1))),1)\n",
    "# Multiply by the pixels by the weight matrix,\n",
    "#  and set a threshold of 0.\n",
    "out = np.matmul(flat, w) > 0.0\n",
    "# Reshape the output as a 2 dimensional list instead of 1 dimensional\n",
    "out = np.reshape(out,(-1,1))\n",
    "# Now, concatenate this list it itself three times to make something\n",
    "#  like a color. Reshape the resulting list into the shape of the original\n",
    "#  image.\n",
    "newarr = np.reshape(np.concatenate((out, out, out),1),arr.shape)\n",
    "# Display the image\n",
    "display(image.array_to_img(newarr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EV9RKiRjMkah"
   },
   "source": [
    "With this classifier, we can replace the background with a new image of a forest\n",
    "\n",
    "We download the image below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gaflJmPXgAC-",
    "outputId": "3fdfed2d-bbe1-49cd-f3f4-d109b47802ab"
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/mlittmancs/great_courses_ml/raw/master/imgs/forest.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UvtT5atwMnnw"
   },
   "source": [
    "We display the image of the forest, `img` below and covert the image into an array, `bkg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dO2w64SeYjhE",
    "outputId": "584ebb29-5be9-418c-cfd5-358a5ed66fd1"
   },
   "outputs": [],
   "source": [
    "img = image.load_img(\"forest.jpg\")\n",
    "\n",
    "display(img)\n",
    "\n",
    "bkg = image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXSVGHANP86Z"
   },
   "source": [
    "`composite` creates a new image based on a mask.  For each pixel in the new image:\n",
    "\n",
    "- If the `mask` predicts the pixel to be in the background, we include the corresponding pixel from `background`.  \n",
    "- If the `mask` predicts predicts the pixel to be in the foreground, we include the corresponding pixel from the `foreground`\n",
    "\n",
    "We then display the `composite` of our prediction mask, `newarr`, the original photo, `arr`, and our forest image, `bkg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-iPFNhhF1vaP",
    "outputId": "8ab0dcb7-a7d5-4698-ca63-7f20a2decaac"
   },
   "outputs": [],
   "source": [
    "def composite(mask, foreground, background):\n",
    "  ishift = 157\n",
    "  print(mask.shape)\n",
    "  for i in range(min(background.shape[0],foreground.shape[0]+ishift)):\n",
    "    for j in range(min(background.shape[1], foreground.shape[1])):\n",
    "      fgi = i - ishift\n",
    "#      if not mask[i][j][0]: background[i][j] = foreground[i][j]\n",
    "      if fgi >= 0 and not mask[fgi][j][0]: background[i][j] = foreground[fgi][j]\n",
    "  display(image.array_to_img(background,scale=False))\n",
    "\n",
    "composite(newarr,arr,bkg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
