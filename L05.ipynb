{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GhyeIVDosAzy"
   },
   "source": [
    "Let's do a simple greenscreen replacement with a machine-learning model.\n",
    "\n",
    "We will:\n",
    "- display an image\n",
    "- pre-process the pixels, labeling background and foreground pixels\n",
    "- train a model to identify green background pixels\n",
    "- use the predictions of the model swap the green screen background for an image of a forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OmxJz39WsEDO"
   },
   "source": [
    "Here we display the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mLDbTVcmDZFl",
    "outputId": "bff450de-2e11-431c-bc90-5b5a189180a4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "img = image.load_img(\"imgs/greenML.png\")\n",
    "\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jx5w3UgAE2cS"
   },
   "source": [
    "Below we trim the edges of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O5ny7M6UflUb",
    "outputId": "76d611c5-2870-4c57-ee6c-4db677c38c63"
   },
   "outputs": [],
   "source": [
    "arr = image.img_to_array(img)\n",
    "# Trim off edges\n",
    "arr = arr[:696,:]\n",
    "display(image.array_to_img(arr,scale=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3ShPb7xE7Rj"
   },
   "source": [
    "In this example, we isolate out the bacground and convert it to a dataset of positive examples, `yesList`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yrdg39l6GMtH",
    "outputId": "2f6672f4-8f45-4db2-e513-4ca50ee63702"
   },
   "outputs": [],
   "source": [
    "# background\n",
    "tmp = arr[:,:360]\n",
    "display(image.array_to_img(tmp,scale=False))\n",
    "\n",
    "yesList = np.reshape(tmp,(-1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_eHUJXK6HVwh"
   },
   "source": [
    "Below we print the number of values in each dimension of `tmp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GzhvRd0kAtk1",
    "outputId": "9c75ba26-e7f2-4791-c5b1-b6b07f3cb65c"
   },
   "outputs": [],
   "source": [
    "tmp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vojIrV_jKKsl"
   },
   "source": [
    "Below we print the number of values in each dimension of `yesList`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "llLbxVFBBoKQ",
    "outputId": "f5a75fca-fb12-42b2-ae0d-b94f08732e05"
   },
   "outputs": [],
   "source": [
    "yesList.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbLvsTBgKnC9"
   },
   "source": [
    "Now we'll isolate out the foreground and make a dataset of foreground pixels called `noList`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qcSqKYtDwqsq",
    "outputId": "07ba1240-1ea9-4f26-c504-37e467abce3d"
   },
   "outputs": [],
   "source": [
    "# foreground\n",
    "tmp = arr[30:,547:620]\n",
    "display(image.array_to_img(tmp,scale=False))\n",
    "\n",
    "noList = np.reshape(tmp,(-1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMoczmlvL86-"
   },
   "source": [
    "Below is the number of values in each dimension of the full image, corresponding to the height, width, and RGB (red, green, blue) colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uf1CSKMBAIWl",
    "outputId": "8f4e2a2e-ed51-46b8-9435-5eb918fe3da3"
   },
   "outputs": [],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mluPsOFNL_i8"
   },
   "source": [
    "We finalize our dataset here, with a variable `alldat` which cointains our list of pixels, and `labs` which is our list of labels for each pixel, `1` for green background pixels and `0` for foreground pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mfPVKGHoenU2"
   },
   "outputs": [],
   "source": [
    "# Build a list of pixels for both positive and negative examples.\n",
    "alldat = np.concatenate((yesList,noList))\n",
    " \n",
    "# labels\n",
    "labs = np.concatenate((np.ones(len(yesList)), np.zeros(len(noList))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlYPmhdkMDIQ"
   },
   "source": [
    "Here, we'll build a classifier to separate the background from the foreground\n",
    "\n",
    "We define a `loss` function.  The `loss` takes in our data, `alldat`, our labels `labs`, and our current weights, `w`.  We will make adjustments to `w` based on this loss function.  To make a prediction, we will multiply `w` by `alldat`, and pass it through a sigmoid function to get our predictions, `y`.  We will then compare our predictions `y` to their true labels `labs` using a squared loss, the sum of the squared difference between `labs`, our true labels, and `y` our predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z03-JVB_eqHJ"
   },
   "outputs": [],
   "source": [
    "# Add an additional column to the data corresponding to \n",
    "#  the offset parameter.\n",
    "alldat = np.concatenate((alldat,np.ones((len(alldat),1))),1)\n",
    "\n",
    "# Compute the loss of the rule specified by weights w with respect\n",
    "#  to the data alldat labeled with labs\n",
    "# Shapes:\n",
    "# * w: (4,)\n",
    "# * alldat: (299178, 4)\n",
    "# * labs: (299178,)\n",
    "def loss(w, alldat, labs):\n",
    "  # Compute a weighted sum for each instance\n",
    "  h = np.matmul(alldat,w)\n",
    "  # transform the sum using the sigmoid function\n",
    "  y = 1/(1 + np.exp(-h))\n",
    "  # take the difference between the labels and the output of the \n",
    "  #  sigmoid, squared, then sum up over all instances to get the \n",
    "  #  total loss.\n",
    "  loss = np.sum((labs - y)**2)\n",
    "  return(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FUhyszdcMKN5"
   },
   "source": [
    "To see how our `loss` function works, we'll print ou the loss of 10 random sets of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oa7hN6xSQfiH",
    "outputId": "7daf01cc-cf33-4490-bc96-119588cc8aad"
   },
   "outputs": [],
   "source": [
    "# repeat 10 times\n",
    "for i in range(10):\n",
    "  # pick a random vector of weights, with values between -1 and 1\n",
    "  w = np.random.random(4)*2-1\n",
    "  # report the loss\n",
    "  print(w, loss(w, alldat, labs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-vkgAKUMNFC"
   },
   "source": [
    "Now we'll train the model, by creating a `fit` function to fit the model to the data.  We will update the weights through gradient descent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l44hJI6tXvox",
    "outputId": "fa7a591a-bc0c-4be8-9f22-3f5409b54193"
   },
   "outputs": [],
   "source": [
    "# The last column of the input was set to 1, which was very small compared to\n",
    "# other columns (with values between 0 and 255). Setting it to a slight larger\n",
    "# number makes the fitting faster, but too large a value appears to degrade\n",
    "# the result. After some test runs, I selected 5.\n",
    "multiplier = 5.0\n",
    "alldat[:, 3] = multiplier\n",
    "\n",
    "# Limits for the weights.\n",
    "low_limit  = np.array([-2.0, -2.0, -2.0, -2.0])\n",
    "high_limit = np.array([ 2.0,  2.0,  2.0,  2.0])\n",
    "\n",
    "def new_weight(w, alpha, delta_w):\n",
    "  # Calculate new weight, ensuring all values are within the limits given above.\n",
    "  neww = w + alpha * delta_w\n",
    "  neww = np.where(neww >  low_limit, neww,  low_limit)\n",
    "  neww = np.where(neww < high_limit, neww, high_limit)\n",
    "  return neww\n",
    "\n",
    "def fit(w,alldat,labs):\n",
    "  count = 0\n",
    "  while True:\n",
    "    # The next few lines compute the gradient of the loss function.\n",
    "    # delta_w is the change in the weights suggested by the gradient\n",
    "    # h[i] = sum_j(alldat[i,j] * w[j])\n",
    "    # y[i] = 1 / (1 + exp(-h[i]))\n",
    "    # loss = sum_i(labs[i] - y[i])\n",
    "    # delta_w[j] = - partial(loss) / partial(w[j])\n",
    "    #   = sum_i((labs[i] - y[i]) * y[i]**2 * exp(-h[i]) * alldat[i,j])\n",
    "    h = np.matmul(alldat,w)\n",
    "    y = 1/(1 + np.exp(-h))\n",
    "    delta_w = np.add.reduce(np.reshape((labs-y) * np.exp(-h)*y**2,(len(y),1)) * alldat)\n",
    "\n",
    "    previous_loss = current_loss = loss(w,alldat,labs)\n",
    "    # Every 100 iterations, let’s\n",
    "    #  take a peek at the weights, the delta,\n",
    "    #  and the current loss\n",
    "    count += 1\n",
    "    if count % 100 == 0:\n",
    "      print('[%.4f %.4f %.4f %.4f] [%.4f %.4f %.4f %.4f] %.4f' % (*w, *delta_w, current_loss))\n",
    "\n",
    "    # If length of delta_w is greater than 1, normalize it to a unit vector,\n",
    "    # so we don't make moves that are to large.\n",
    "    delta_w_size = np.sqrt(sum(delta_w * delta_w))\n",
    "    if delta_w_size > 1.0:\n",
    "      delta_w /= delta_w_size\n",
    "\n",
    "    # alpha represents how big of a step we’ll\n",
    "    #  be taking in the direction of the derivative.\n",
    "    #  It’s called the learning rate.\n",
    "    alpha = 1.0\n",
    "\n",
    "    while alpha*max(abs(delta_w)) > 1e-5:\n",
    "      alpha /= 2\n",
    "      # if we take a step of size alpha and update\n",
    "      #  the weights, we’ll get new weights neww.\n",
    "      neww = new_weight(w, alpha, delta_w)\n",
    "      new_loss = loss(neww, alldat, labs)\n",
    "      #print(alpha, current_loss, new_loss, neww)\n",
    "      if new_loss < current_loss:\n",
    "        current_loss = new_loss\n",
    "        w = neww\n",
    "\n",
    "    if current_loss >= previous_loss - 2e-4:\n",
    "      break\n",
    "\n",
    "  return(w)\n",
    "\n",
    "# We could have used random initial weights, but for consistency we use all zeros.\n",
    "w = np.zeros(4)\n",
    "w = fit(w,alldat,labs)\n",
    "\n",
    "# Absorb the last column value into weight, and then reset the last column back to 1, \n",
    "w[3] *= multiplier\n",
    "alldat[:, 3] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B6p4xPqaMTds"
   },
   "source": [
    "We'll now print the final `loss` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KQI6jeTeeBCC",
    "outputId": "56c851c6-eb1a-4f79-b721-99fd8c264317"
   },
   "outputs": [],
   "source": [
    "print(loss(w, alldat, labs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-lDOwC9YMcBH"
   },
   "source": [
    "These are the weights of our learned classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LDMfFw-Nc26s",
    "outputId": "100196e3-0560-405f-c8d6-e80222e5e80a"
   },
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6KsBqtiMgiw"
   },
   "source": [
    "Now we'll display the predictions of the classifier for each pixel in our image.  We reshape our image, `arr` and multiply it by our learned weights, `w` to get our predictions for each pixel belonging to the background, `out`.  We convert `out` into a binary array and reshape to display as an image; `newarr` is our binarized prediction image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P6kFOVHAeqV8",
    "outputId": "25942cf6-e742-45d5-ba9a-89f406c090d9"
   },
   "outputs": [],
   "source": [
    "# Turn the pixels in the image into a list\n",
    "flat = np.reshape(arr,(-1,3))\n",
    "# Stick a \"1\" at the end of each color\n",
    "flat = np.concatenate((flat,np.ones((len(flat),1))),1)\n",
    "# Multiply by the pixels by the weight matrix,\n",
    "#  and set a threshold of 0.\n",
    "# Previously, while calculating the loss function during the training,\n",
    "# we pass the matrix multiply results to the sigmoid function. This has\n",
    "# the effect of converting positive values to range (0.5, 1), closer to\n",
    "# the background indicator of 1, and converting negative values to\n",
    "# range (0, 1), closer to the foreground indicator of 0. Here, we just\n",
    "# need the mask, so we can skip sigmoid and use 0 as threshold.\n",
    "out = np.matmul(flat, w) > 0.0\n",
    "# Reshape the output as a 2 dimensional list instead of 1 dimensional\n",
    "out = np.reshape(out,(-1,1))\n",
    "# Now, concatenate this list it itself three times to make something\n",
    "#  like a color. Reshape the resulting list into the shape of the original\n",
    "#  image.\n",
    "newarr = np.reshape(np.concatenate((out, out, out),1),arr.shape)\n",
    "# Display the image\n",
    "display(image.array_to_img(newarr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EV9RKiRjMkah"
   },
   "source": [
    "With this classifier, we can replace the background with a new image of a forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UvtT5atwMnnw"
   },
   "source": [
    "We display the image of the forest, `img` below and covert the image into an array, `bkg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dO2w64SeYjhE",
    "outputId": "584ebb29-5be9-418c-cfd5-358a5ed66fd1"
   },
   "outputs": [],
   "source": [
    "img = image.load_img(\"imgs/forest.jpg\")\n",
    "\n",
    "display(img)\n",
    "\n",
    "bkg = image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXSVGHANP86Z"
   },
   "source": [
    "`composite` creates a new image based on a mask.  For each pixel in the new image:\n",
    "\n",
    "- If the `mask` predicts the pixel to be in the background, we include the corresponding pixel from `background`.  \n",
    "- If the `mask` predicts predicts the pixel to be in the foreground, we include the corresponding pixel from the `foreground`\n",
    "\n",
    "We then display the `composite` of our prediction mask, `newarr`, the original photo, `arr`, and our forest image, `bkg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-iPFNhhF1vaP",
    "outputId": "8ab0dcb7-a7d5-4698-ca63-7f20a2decaac"
   },
   "outputs": [],
   "source": [
    "def composite(mask, foreground, background):\n",
    "  ishift = 157\n",
    "  print(mask.shape)\n",
    "  for i in range(min(background.shape[0],foreground.shape[0]+ishift)):\n",
    "    for j in range(min(background.shape[1], foreground.shape[1])):\n",
    "      fgi = i - ishift\n",
    "#      if not mask[i][j][0]: background[i][j] = foreground[i][j]\n",
    "      if fgi >= 0 and not mask[fgi][j][0]: background[i][j] = foreground[fgi][j]\n",
    "  display(image.array_to_img(background,scale=False))\n",
    "\n",
    "composite(newarr,arr,bkg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
