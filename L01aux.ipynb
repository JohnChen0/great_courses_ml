{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOhk6w7s2A5B"
   },
   "source": [
    "We'll do a simple greenscreen replacement with a machine-learning model.\n",
    "\n",
    "In the following code cells, we will:\n",
    "- download and display an image\n",
    "- pre-process the pixels, labeling background and foreground pixels\n",
    "- train a model to identify green background pixels\n",
    "- use the predictions of the model to swap the green screen background for an image of a forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8PFoSOH4XZiv"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from keras.preprocessing import image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whuuAbSS2TdF"
   },
   "source": [
    "Display the image using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 730
    },
    "id": "mLDbTVcmDZFl",
    "outputId": "31fbaf1c-4b87-4b56-cb03-86342dbb46da"
   },
   "outputs": [],
   "source": [
    "# img is an object of type PIL.Image.Image.\n",
    "img = keras.utils.load_img(\"imgs/greenML.png\")\n",
    "\n",
    "# display is a built-in IPython function.\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "naq9oJro2yzp"
   },
   "source": [
    "Display a cropped version of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "id": "O5ny7M6UflUb",
    "outputId": "ff61a730-b35f-4fbc-e968-994f52d6ef25"
   },
   "outputs": [],
   "source": [
    "# arr is np.ndarray of shape height * width * 3, i.e., arr.shape == (713, 1215, 3)\n",
    "arr = keras.utils.img_to_array(img)\n",
    "# Trim off edges\n",
    "# Original code uses arr[:697,:], but that isn't quite complete, such that at the\n",
    "# bottom of the cropped image, there is one row of dark gray pixels (color (52, 52, 52)).\n",
    "arr = arr[:696,:]\n",
    "display(tf.keras.preprocessing.image.array_to_img(arr,scale=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following few cells extract the background and foreground colors from the image, but in the end the extracted information is not used. Instead, the final block of code uses hardcoded background color."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNouAqte70WM"
   },
   "source": [
    "Isolate the background and make a dataset of background pixels, `YesSet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "id": "yrdg39l6GMtH",
    "outputId": "ec00d645-f31f-4c42-95e1-748119c21afb"
   },
   "outputs": [],
   "source": [
    "# background\n",
    "tmp = arr[:,:360]\n",
    "display(tf.keras.preprocessing.image.array_to_img(tmp,scale=False))\n",
    "\n",
    "YesSet = np.reshape(tmp,(-1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evGsCnfEIQkb"
   },
   "source": [
    "Print the number dimensions of `tmp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GzhvRd0kAtk1",
    "outputId": "7902195a-1f69-455d-ef93-a0f988f634cd"
   },
   "outputs": [],
   "source": [
    "tmp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSyMEvRRIXc5"
   },
   "source": [
    "Print the dimensions of `YesSet`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "llLbxVFBBoKQ",
    "outputId": "797cb42c-828f-4189-a7ad-2d8f98224604"
   },
   "outputs": [],
   "source": [
    "YesSet.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cl5q-cYjJWJp"
   },
   "source": [
    "Build `seen` dictionary of the unique pixel colors in `yes_list`.  For all keys in the dictionary, the value is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ACqoSeLO1xFV",
    "outputId": "1842ae03-16d9-43cc-b479-61bdcc71cc59"
   },
   "outputs": [],
   "source": [
    "seen = {}\n",
    "for c in YesSet:\n",
    "  # The original code converts `c` to str before inserting into `seen`,\n",
    "  # and is quite slow. We achieve a major speed-up by using tuple instead.\n",
    "  seen[tuple(c.tolist())] = 1\n",
    "# Convert from tuple to string, to be compatible with the original code.\n",
    "seen = {str(np.array(c)): 1 for c in seen.keys()}\n",
    "len(seen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k6S96Ucf8AZH"
   },
   "source": [
    "Isolate part of the foreground and make a dataset of foreground pixels called `NoSet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 684
    },
    "id": "qcSqKYtDwqsq",
    "outputId": "e70192fe-0fb7-487d-b293-c02af1cc840c"
   },
   "outputs": [],
   "source": [
    "# foreground\n",
    "tmp = arr[30:,547:620]\n",
    "display(tf.keras.preprocessing.image.array_to_img(tmp,scale=False))\n",
    "\n",
    "NoSet = np.reshape(tmp,(-1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LNyD249nLSdo"
   },
   "source": [
    "Dimensions of the full image, corresponding to the height, width, and RGB (red, green, blue) colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uf1CSKMBAIWl",
    "outputId": "5a318f70-4283-45ae-c343-a69b5eda44af"
   },
   "outputs": [],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H1H5hWEs8EYH"
   },
   "source": [
    "We finalize our dataset, with a variable `alldat` cointaining our list of pixels, and `labs` holding our list of labels for each pixel (`0` for green background pixels and `1` for foreground pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mfPVKGHoenU2"
   },
   "outputs": [],
   "source": [
    "# Build a list of pixels for both positive and negative examples.\n",
    "alldat = np.concatenate((YesSet,NoSet))\n",
    " \n",
    "# labels\n",
    "labs = np.concatenate((np.ones(len(YesSet)), np.zeros(len(NoSet))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yI4WBQc3QsdZ"
   },
   "source": [
    "We display the image of the forest, `img` and covert the image into an array, `bkg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 871
    },
    "id": "ysMcEq4cQgmx",
    "outputId": "c8406bc3-95b3-49cf-b278-71171970fbde"
   },
   "outputs": [],
   "source": [
    "img = keras.utils.load_img(\"imgs/forest.jpg\")\n",
    "\n",
    "display(img)\n",
    "\n",
    "bkg = keras.utils.img_to_array(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fghnZqUrGrEQ"
   },
   "source": [
    "Define drawScreen for merging foreground and background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ikWTqVLFNEwi"
   },
   "outputs": [],
   "source": [
    "# Contains some perf optimizations, reducing the run time of the following code\n",
    "# block from 13 seconds to 5 seconds.\n",
    "\n",
    "def distance_square(c1: np.ndarray, c2: np.ndarray):\n",
    "  return ((c1 - c2) ** 2).sum()\n",
    "\n",
    "def drawScreen(c: np.ndarray, d: float,\n",
    "               studio_image: np.ndarray, background_image: np.ndarray):\n",
    "  display_image = studio_image.copy()\n",
    "  for x in range(min(background_image.shape[0],studio_image.shape[0])):\n",
    "    for y in range(min(background_image.shape[1], studio_image.shape[1])):\n",
    "      if distance_square(c, studio_image[x][y]) <= d:\n",
    "        display_image[x][y] = background_image[x][y]\n",
    "  display(tf.keras.preprocessing.image.array_to_img(display_image,scale=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ytf5Eg5EG4lb"
   },
   "source": [
    "Put ML into the forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "id": "G0zG6fGnQXIo",
    "outputId": "0add1bdd-df4f-4488-834f-1ecd67f52484"
   },
   "outputs": [],
   "source": [
    "drawScreen(np.array([0.3,174.5,46.7]), 1000.0, arr, bkg)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "L01aux.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
